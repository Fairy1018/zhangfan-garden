# 一、背景
项目开发时，本地和测试服上mongo是单点机器，而线上mongo则是复制集模式。
考虑到项目中读请求数远超写请求数，而复制集中常用读写分离的方式减轻主库读压力。即读从库，写主库。
但主库和从库之间同步存在一定延时，因此设置读写分离无法满足数据即时性要求。
在查阅各方资料，并且和DBA同学讨论后，最后得出了数据安全性和即时性两种解决方案。相关知识储备和最终方案如下：


# 二、知识储备

## 2.1 写操作设置
复制集模式下，写操作默认是在primary进行，因此只需要关心：操作到达在多少个节点上才算成功。

这部分由writeConcern控制，有以下几种方式
- **w:number**
  number表示写入节点的数量，w:0表示不确认写入到节点即返回，w:1表示写入到1个节点则返回 (**mongo默认的write concern**)
- **w:majority**
  表示写入到大多数节点则返回，一般采用此设置
- **w:all**
  表示写入到全部节点则返回
- **j:true**
  写操作落在journal文件中才算成功，重要数据会使用该设置。如果没有设置，则写操作到达内存即算成功

## 2.2 读操作设置
复制集模式下，读操作需要关心的是：从哪里读（readPreference）和读什么样的数据(readConcern)。即关注读取节点的位置和数据隔离性。

readPreference 选项指定节点位置，有以下几种方式：
- **primary** 
  只选择主节点。
- **primaryPreferred**
  优先选择主节点，如不可用（故障转移期间）则选择从节点。
- **secondary**
  只选择从节点
- **secondaryPreferred**
  优先选择从节点，如不可用则选择主节点，读写分离时使用
- **nearest**
   选择最近的节点，通过ping time决定

readConcern选项类似于关系型数据库的隔离级别，有以下几种可选值：
- **avaliable**
  读取所有可用的数据
- **local**
  读取所有可用且属于当前分片的数据。复制集中和avaliable没有区别，在分片集迁移过程有区别
- **majority**
  读取大多数节点上已提交的数据，**防止回滚时产生脏读。** 具体判断方法是每个节点查看自己的同步视图
- **lineariable**
  只读取大多数节点确认的数据，和majority区别是保证绝对的操作线性顺序
- **snapshot**
  只在多文档事务中生效，能保证多文档事务中可重复读


# 三、解决方案

## 3.1 由主库承担读写任务
```
writeConcern:majority
```
原理：写操作在未落到大多数节点之前，都是不安全的，因此采用``majority写``防止脏读。读写的节点位置采用默认设置，即在主库读写，保证在写操作完成后可读取到最新数据



## 3.2 读写分离下的解决方案
```
writeConcern:majority,
readPerference:secondary,
readConcern:majority
```
原理：majority写理由同上，保证了在多数节点上数据已落地。
如果设置读从库，则读的数据需为majority级别，即为上一次多数节点落地的数据。``majority读``搭配``majority写``，保证读到最新数据。


## 3.3 实验验证
验证复制集中读写级别的设置是否生效。

### 3.3.1 验证secondary读
步骤：
0.在代码中设置  ``readPreference:secondary``
1.关闭两个从节点同步  ``db.fsyncLock()``
2.修改一条数据，默认在主节点上修改，更改为新数据
3.查询修改的数据，验证是否为旧数据。旧数据表明读请求打到了未同步的从节点
4.结束，打开两个从节点同步  ``db.fsyncUnlock()``

### 3.3.2 验证majority读
步骤:
0.在代码中设置 ``writeConcern:majority``
1.关闭两个从节点同步  ``db.fsyncLock()``
2.修改一条数据，默认在主节点上修改，更改为新数据
3.查询修改的数据，验证是否为旧数据。旧数据表明读到了majority节点的数据
4.打开一个从节点同步 ``db.fsyncUnlock()``
5.查询修改的数据，验证是否为新数据。新数据表明从节点已和主节点同步，majority的数据为新数据
6.结束，打开两个从节点同步  ``db.fsyncUnlock()``

### 3.3.3 majority读和secondary读同时存在的情况
步骤:
0.在代码中设置 ``writeConcern；majority, readPreference:secondary``
1.关闭两个从节点同步  ``db.fsyncLock()``
2.修改一条数据，默认在主节点上修改为新数据
3.查询修改的数据，验证是否为旧数据。旧数据表明两个从节点上的majority都为旧数据
4.打开一个从节点同步 ``db.fsyncUnlock()``
5.查询修改的数据，验证数据是新数据还是旧数据？

Answer：这种情况下新旧数据都有。原因是second节点有两个，已同步的从节点的视图上看到自己和主节点都更新了，所以其majority为新数据。而未同步的节点的视图上，它显示的三个节点都未更新，所以其majority为旧数据。

# 四、总结

笔者使用node+mongoose+mongodb 实现，需注意：
1.connect时需加上``useUnfiedTopology:true``，进行服务发现和监视（复制集和分片集群），否则检测不到复制集
2.除了connect选项连接时可以设置writeConcern\readConcern\readPerference,在schema中也可以设置，这两处都检查到
3.在看新数据还是旧数据时，多试几次。一次查询可能是某个节点的个例，多次查询可能出现其他的结果

笔者建议：对于重要的数据，可以使用majority写保证安全性。如果有时效性，例如下订单后立刻转到订单详情界面，可以采用默认的primary读。而时效性要求不高的数据，例如历史订单等，可以使用second读以减轻主节点压力。

以上是笔者对mogno中数据安全性和即时性的理解，如果有不足之处，欢迎各位拍砖～